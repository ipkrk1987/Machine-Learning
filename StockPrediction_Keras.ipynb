{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StockPrediction_Keras.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "xzxLdgHcsI5a"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipkrk1987/Machine-Learning/blob/master/StockPrediction_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFkK7l6w5Tzt"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDfo34rFZPP6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import plot_model\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nQ0YFuL1cpY"
      },
      "source": [
        "\n",
        "def reverse(data):\n",
        "    data = data[::-1].reset_index(drop=True); \n",
        "    return data;\n",
        "def mom_nextDay(df, n):  \n",
        "    cl = df['Close']; \n",
        "    M = pd.Series((cl.pct_change(periods = n) >0).astype(int), name='Mom')\n",
        "    df = df.join(M)\n",
        "    return df\n",
        "def momentum(df, n):  \n",
        "    cl = df['Close']; \n",
        "    M = pd.Series(cl.pct_change(periods = n), name='Mom')\n",
        "    df = df.join(M)\n",
        "    return df\n",
        "def moving_average(df, n,name,inverse=False,field='Close'):\n",
        "    \"\"\"Calculate the moving average for the given data.\n",
        "    \n",
        "    :param df: pandas.DataFrame\n",
        "    :param n: \n",
        "    :return: pandas.DataFrame\n",
        "    \"\"\"\n",
        "    if inverse:\n",
        "        MA = pd.Series(df[field]/df[field].rolling(n, min_periods=n).mean(), name=name)\n",
        "    else:\n",
        "        MA = pd.Series(df[field].rolling(n, min_periods=n).mean(), name=name)\n",
        "    df = df.join(MA)\n",
        "    return df\n",
        "\n",
        "def exponential_moving_average(df, n,name,inverse=False,field='Close'):\n",
        "    \"\"\"\n",
        "    \n",
        "    :param df: pandas.DataFrame\n",
        "    :param n: \n",
        "    :return: pandas.DataFrame\n",
        "    \"\"\"\n",
        "    \n",
        "    #print(field)\n",
        "    if inverse:\n",
        "        EMA = pd.Series(1/df[field].ewm(span=n, min_periods=n).mean(), name=name)\n",
        "    else:\n",
        "        EMA = pd.Series(df[field].ewm(span=n, min_periods=n).mean(), name=name)\n",
        "    df = df.join(EMA)\n",
        "    return df\n",
        "\n",
        "\n",
        "def weighted_moving_average(df, n,name,inverse=False,field='Close'):\n",
        "    \"\"\"\n",
        "    \n",
        "    :param df: pandas.DataFrame\n",
        "    :param n: \n",
        "    :return: pandas.DataFrame\n",
        "    \"\"\"\n",
        "    weights = np.arange(1,n+1,1)\n",
        "    sum_weights = np.sum(weights)    \n",
        "    \n",
        "    if inverse:\n",
        "        val = (df[field]\n",
        "        .rolling(window=n, center=True)\n",
        "        .apply(lambda x: sum_weights/np.sum(weights*x), raw=False)\n",
        "        )\n",
        "    else:\n",
        "        val = (df[field]\n",
        "        .rolling(window=n, center=True)\n",
        "        .apply(lambda x: np.sum(weights*x) / sum_weights, raw=False)\n",
        "        )\n",
        "    \n",
        "    \n",
        "    WMA = pd.Series(val, name=name)\n",
        "    df = df.join(WMA)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr4BwHBx1k-Z"
      },
      "source": [
        "def generateData(file, n=5, mas = [3,8,15,20,30,40,50,60,75,100,125,150,200]):\n",
        "    stocks = pd.read_csv(file, skiprows=2,error_bad_lines=False);   \n",
        "    \n",
        "    stocks.columns = ['TICKER','DATE','OPEN','HIGH','LOW','Close','VOLUME']\n",
        "    stocks = stocks.sort_values(by=['DATE'])    \n",
        "    sr= stocks.reset_index(drop=True)\n",
        "    s_ma = sr\n",
        "    for ma in range(1, 201, 10):         \n",
        "         s_ma = weighted_moving_average(s_ma,ma,\"s_\"+str(ma),True,'Close')\n",
        "       \n",
        "    print('sma generated')\n",
        "    s_ma  = s_ma.dropna()    \n",
        "    s_mamo = momentum(s_ma,n)    \n",
        "    s_mamo.loc[:,'Mom']  = s_mamo.loc[:,'Mom'].shift(-n)\n",
        "    s_mamo = s_mamo.iloc[n+5:]\n",
        "    sr = s_mamo\n",
        "    sr_null = sr[sr.Mom.isna()]\n",
        "    sr = sr.dropna()    \n",
        "    sr.loc[:,'buy'] = (sr.Mom > 0).astype('int')    \n",
        "    return sr,sr_null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqvem2cV15jf"
      },
      "source": [
        "\n",
        "\n",
        "def testAdaBoost(file,days):\n",
        "    steps = [('clf', AdaBoostClassifier())]\n",
        "    pipe = Pipeline(steps) # define the pipeline object.\n",
        "    etc  = ExtraTreeClassifier()\n",
        "    dtc  = DecisionTreeClassifier()   \n",
        "    nb   = GaussianNB()\n",
        "    parameteres = {'clf__n_estimators':[10],'clf__random_state':[0],'clf__base_estimator':[etc,dtc]}\n",
        "    grid = GridSearchCV(pipe, param_grid=parameteres, cv=3)   \n",
        "    sr,sr_null = generateData(file,days)   \n",
        "    pca_df, pca_dfnull = getPCAData(sr,sr_null)\n",
        "    Y = pca_df.buy\n",
        "    X_train, X_test, y_train, y_test = train_test_split(pca_df, Y, test_size=0.1, random_state=42,stratify = Y)\n",
        "    grid.fit(X_train,y_train)    \n",
        "    Ypred_test = grid.predict(X_test);\n",
        "    y_current = grid.predict(pca_dfnull)   \n",
        "    score_grid = accuracy_score(y_test,Ypred_test)#grid.score(dftest,Ytest)\n",
        "    return score_grid,y_current,sr_null.tail(1)\n",
        "\n",
        "\n",
        "def testMLP(file,days):\n",
        "    steps = [('clf', MLPClassifier())]\n",
        "    pipe = Pipeline(steps) # define the pipeline object. \n",
        "   \n",
        "    parameteres = {'clf__hidden_layer_sizes':[(100,1), (100,2), (100,3)],'clf__activation':[ 'logistic']}\n",
        "    grid = GridSearchCV(pipe, param_grid=parameteres, cv=3) \n",
        "   \n",
        "    sr,sr_null = generateData(file,days)   \n",
        "    pca_df, pca_dfnull = getPCAData(sr,sr_null)\n",
        "    Y = pca_df.buy\n",
        "    X_train, X_test, y_train, y_test = train_test_split(pca_df, Y, test_size=0.1, random_state=42,stratify = Y)\n",
        "    grid.fit(X_train,y_train)    \n",
        "    Ypred_test = grid.predict(X_test);\n",
        "    y_current = grid.predict(pca_dfnull)   \n",
        "    score_grid = accuracy_score(y_test,Ypred_test)#grid.score(dftest,Ytest)\n",
        "    print(grid.best_params_)\n",
        "    return score_grid,y_current,sr_null.tail(1)\n",
        "\n",
        "def testRandomForest(file,days):     \n",
        "    grid = RandomForestClassifier()   \n",
        "    return testClassifier(file,days,grid)\n",
        "\n",
        "def testXGBooster(file,days):\n",
        "    grid =  xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
        "    return testClassifier(file,days,grid)\n",
        "\n",
        "\n",
        "def testPerceptron(file,days):    \n",
        "    grid = Perceptron()   \n",
        "    return testClassifier(file,days,grid)\n",
        "\n",
        "\n",
        "def testClassifier(file,days,classifier):    \n",
        "    grid = classifier   \n",
        "    sr,sr_null = generateData(file,days)   \n",
        "    pca_df, pca_dfnull = getPCAData(sr,sr_null)\n",
        "    Y = sr.buy    \n",
        "    \n",
        "    \n",
        "    \n",
        "    ## Split data in half.\n",
        "    X_train, X_test, y_train, y_test = train_test_split(pca_df, Y, test_size=0.8, random_state=42,stratify = Y)\n",
        "    grid.fit(X_train,y_train)     \n",
        "    \n",
        "     \n",
        "    \n",
        "    y_train_pred = grid.predict(X_train)\n",
        "    y_train_proba = grid.predict_proba(X_train) \n",
        "   \n",
        "    \n",
        "    y_null_proba = grid.predict_proba(pca_dfnull)    \n",
        "    y_null_pred = grid.predict(pca_dfnull) \n",
        "    \n",
        "    \n",
        "    #= grid.predict(X_test)\n",
        "    y_test_proba = grid.predict_proba(X_test)\n",
        "    y_test_pred = grid.predict(X_test) \n",
        "    \n",
        "    \n",
        "#     cnew2 = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42) \n",
        "#     cnew2 = trainProbabilites(y_train_proba,y_train,cnew2)\n",
        "#     y_test_pred = cnew2.predict(y_test_proba)\n",
        "    \n",
        "    #### This is used to compute the accuracy and cm for normal algorithm###\n",
        "    acc = accuracy_score(y_test,y_test_pred)\n",
        "    cm = confusion_matrix(y_test,y_test_pred)\n",
        "    cr = classification_report(y_test,y_test_pred)\n",
        "    f1 = f1_score(y_test,y_test_pred)\n",
        "    \n",
        "\n",
        "         \n",
        "     \n",
        "    \n",
        "    \n",
        "    #add probabilites of classes.\n",
        "    sr_null[grid.classes_] = pd.DataFrame(y_null_proba[-days:], index=sr_null.index) \n",
        "    ## Add last week values to the newdata to be predicted.\n",
        "    sr_null[['PC']] = pd.DataFrame(sr.Close.tail(days).values, index=sr_null.index)     \n",
        "    sr_null[['Pred']] = pd.DataFrame(y_null_pred, index=sr_null.index)\n",
        "    return f1,acc,cm,cr,sr_null,sr, y_null_proba,y_null_pred,y_test_proba,y_train_proba,y_test,y_train\n",
        "\n",
        "\n",
        "def trainProbabilites(proba_train,y_train,classifier):\n",
        "    classifier.fit(proba_train,y_train)    \n",
        "    return classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nNp2wCyKfVb"
      },
      "source": [
        "def getPCAData(sr,sr_null):\r\n",
        "    imputer = KNNImputer(n_neighbors=3)\r\n",
        "    #imputer.fit_transform(X)\r\n",
        "    ##### Get PCA DATA FOR STOCK DATA WITH MOM.\r\n",
        "    \r\n",
        "    df  = sr.loc[:, sr.columns.str.startswith('s_')]    \r\n",
        "    scaler = MinMaxScaler()     \r\n",
        "    pca = PCA() # create a PCA object\r\n",
        "    pca.fit(df) # do the math\r\n",
        "    pca_data = pca.transform(df) # get PCA coordinates for scaled_data\r\n",
        "    per_var = np.round(pca.explained_variance_ratio_* 100, decimals=1)\r\n",
        "    labels = ['PC' + str(x) for x in range(1, len(per_var)+1)]\r\n",
        "    #the following code makes a fancy looking plot using PC1 and PC2\r\n",
        "    pca_df = pd.DataFrame(pca_data, columns=labels)   \r\n",
        "    x = df.var(axis=1)        \r\n",
        "    pca_df = pca_df.join(pd.Series(x,name='x')) \r\n",
        "    X = imputer.fit_transform(pca_df)         \r\n",
        "    pca_df = pd.DataFrame(X)\r\n",
        "    \r\n",
        "    ##### Get PCA DATA FOR STOCK DATA WITH NO MOM.\r\n",
        "    \r\n",
        "    df_null  = sr_null.loc[:, sr_null.columns.str.startswith('s_')] \r\n",
        "    df_null = scaler.fit_transform(df_null)  \r\n",
        "    pca_data_null = pca.transform(df_null) # get PCA coordinates for scaled_data    \r\n",
        "    pca_df_null = pd.DataFrame(pca_data_null, columns=labels)   \r\n",
        "    x_null = df_null.var(axis=1)\r\n",
        "    pca_df_null = pca_df_null.join(pd.Series(x_null,name='x'))\r\n",
        "    X_null = imputer.fit_transform(pca_df_null)         \r\n",
        "    pca_df_null = pd.DataFrame(X_null)\r\n",
        "   \r\n",
        "    \r\n",
        "    return pca_df,pca_df_null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni-EvXtdkgNJ"
      },
      "source": [
        "Build the model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHWr2kUS2BMP"
      },
      "source": [
        "import os\n",
        "directory = os.path.join(\"../content/stockdata\")\n",
        "print(directory)\n",
        "days = 20\n",
        "scores = []\n",
        "for root,dirs,files in os.walk(directory):\n",
        "    for f in files:\n",
        "        if f.endswith(\".csv\"):\n",
        "            fn = os.path.join(directory,f) \n",
        "            try:     \n",
        "              print(fn) \n",
        "              sr,sr_null = generateData(fn,days)               \n",
        "              pca_df, pca_dfnull = getPCAData(sr,sr_null)\n",
        "              print(pca_df.shape)\n",
        "              Y = sr.buy.values\n",
        "\n",
        "              onehot_encoder=OneHotEncoder(sparse=False)\n",
        "              reshaped=Y.reshape(len(Y), 1)\n",
        "              y_onehot=onehot_encoder.fit_transform(reshaped)\n",
        "             \n",
        "              train_x, test_x, train_y, test_y = train_test_split(pca_df, y_onehot, test_size=0.9, random_state=42,stratify = Y)\n",
        "              model = Sequential()\n",
        "              model.add(Dense(12, input_dim=21, activation='relu'))\n",
        "              model.add(Dense(2, activation='softmax'))\n",
        "              model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "              # Test on unseen data\n",
        "              model.fit(train_x, train_y, verbose=0, batch_size=5, epochs=200)\n",
        "              print(model.summary())\n",
        "              results = model.evaluate(test_x, test_y)\n",
        "\n",
        "              print('Final test set loss: {:4f}'.format(results[0]))\n",
        "              print('Final test set accuracy: {:4f}'.format(results[1]))  \n",
        "\n",
        "             \n",
        "            except Exception as inst:\n",
        "              print(inst)\n",
        "              #print(\"Exception occured\",file)\n",
        "             "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flv841Lgp2DL"
      },
      "source": [
        "**Print the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CMin7eIqbkn"
      },
      "source": [
        "\n",
        "#!pip install keras_sequential_ascii\n",
        "from keras_sequential_ascii import keras2ascii\n",
        "keras2ascii(model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}